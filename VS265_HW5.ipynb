{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "SID: 3040752562"
      ],
      "metadata": {
        "id": "hUWNdeDM5YIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def circular_convolve(a, b):\n",
        "    \"\"\"Circular convolution of two vectors.\"\"\"\n",
        "    return np.real(np.fft.ifft(np.fft.fft(a) * np.fft.fft(b)))\n",
        "\n",
        "def simulate(n=2048):\n",
        "    \"\"\"Perform one simulation of the experiment.\"\"\"\n",
        "    # Base vector names\n",
        "    base_vector_names = [\n",
        "        'person', 'dog', 'cat', 'mouse', 'bite', 'flee', 'cause', 'stroke', 'lick',\n",
        "        'biteagt', 'biteobj', 'fleeagt', 'fleefrom', 'causeantc', 'causecnsq',\n",
        "        'strokeagt', 'strokeobj', 'lickagt', 'lickobj'\n",
        "    ]\n",
        "\n",
        "    # ID vector names\n",
        "    id_vector_names = [\n",
        "        'idjane', 'idjohn', 'idfred', 'idspot', 'idfido', 'idrover', 'idfelix', 'idmort'\n",
        "    ]\n",
        "\n",
        "    # Generate base vectors\n",
        "    base_vectors = {}\n",
        "    for name in base_vector_names:\n",
        "        base_vectors[name] = np.random.normal(0, 1/np.sqrt(n), n)\n",
        "\n",
        "    # Generate id vectors\n",
        "    id_vectors = {}\n",
        "    for name in id_vector_names:\n",
        "        id_vectors[name] = np.random.normal(0, 1/np.sqrt(n), n)\n",
        "\n",
        "    # Token vectors\n",
        "    token_vectors = {}\n",
        "    token_vectors['jane'] = base_vectors['person'] + id_vectors['idjane']\n",
        "    token_vectors['john'] = base_vectors['person'] + id_vectors['idjohn']\n",
        "    token_vectors['fred'] = base_vectors['person'] + id_vectors['idfred']\n",
        "    token_vectors['spot'] = base_vectors['dog'] + id_vectors['idspot']\n",
        "    token_vectors['fido'] = base_vectors['dog'] + id_vectors['idfido']\n",
        "    token_vectors['rover'] = base_vectors['dog'] + id_vectors['idrover']\n",
        "    token_vectors['felix'] = base_vectors['cat'] + id_vectors['idfelix']\n",
        "    token_vectors['mort'] = base_vectors['mouse'] + id_vectors['idmort']\n",
        "\n",
        "    # Normalize all vectors to unit length\n",
        "    for key in base_vectors:\n",
        "        base_vectors[key] /= np.linalg.norm(base_vectors[key])\n",
        "    for key in id_vectors:\n",
        "        id_vectors[key] /= np.linalg.norm(id_vectors[key])\n",
        "    for key in token_vectors:\n",
        "        token_vectors[key] /= np.linalg.norm(token_vectors[key])\n",
        "\n",
        "    # Build HRRs for the probe and episodes\n",
        "    def build_event(action, agent_role, agent, object_role, obj):\n",
        "        \"\"\"Build an event (sentence) according to Plate's thesis. \"\"\"\n",
        "        return base_vectors[action] + \\\n",
        "               circular_convolve(base_vectors[agent_role], token_vectors[agent]) + \\\n",
        "               circular_convolve(base_vectors[object_role], token_vectors[obj])\n",
        "\n",
        "    # Probe: Spot bit Jane, causing Jane to flee from Spot\n",
        "    Pbite = build_event('bite', 'biteagt', 'spot', 'biteobj', 'jane')\n",
        "    Pflee = build_event('flee', 'fleeagt', 'jane', 'fleefrom', 'spot')\n",
        "    Pobjects = token_vectors['jane'] + token_vectors['spot']\n",
        "    P = base_vectors['cause'] + Pobjects + Pbite + Pflee + \\\n",
        "        circular_convolve(base_vectors['causeantc'], Pbite) + \\\n",
        "        circular_convolve(base_vectors['causecnsq'], Pflee)\n",
        "\n",
        "    # Initialize a dictionary to store episodes\n",
        "    episodes = {}\n",
        "\n",
        "    # E1: Fido bit John, causing John to flee from Fido\n",
        "    E1bite = build_event('bite', 'biteagt', 'fido', 'biteobj', 'john')\n",
        "    E1flee = build_event('flee', 'fleeagt', 'john', 'fleefrom', 'fido')\n",
        "    E1objects = token_vectors['john'] + token_vectors['fido']\n",
        "    E1 = base_vectors['cause'] + E1objects + E1bite + E1flee + \\\n",
        "         circular_convolve(base_vectors['causeantc'], E1bite) + \\\n",
        "         circular_convolve(base_vectors['causecnsq'], E1flee)\n",
        "    episodes['E1'] = E1\n",
        "\n",
        "    # E2: Fred bit Rover, causing Rover to flee from Fred (cross-mapping)\n",
        "    E2bite = build_event('bite', 'biteagt', 'fred', 'biteobj', 'rover')\n",
        "    E2flee = build_event('flee', 'fleeagt', 'rover', 'fleefrom', 'fred')\n",
        "    E2objects = token_vectors['fred'] + token_vectors['rover']\n",
        "    E2 = base_vectors['cause'] + E2objects + E2bite + E2flee + \\\n",
        "         circular_convolve(base_vectors['causeantc'], E2bite) + \\\n",
        "         circular_convolve(base_vectors['causecnsq'], E2flee)\n",
        "    episodes['E2'] = E2\n",
        "\n",
        "    # E3: Felix bit Mort, causing Mort to flee from Felix\n",
        "    E3bite = build_event('bite', 'biteagt', 'felix', 'biteobj', 'mort')\n",
        "    E3flee = build_event('flee', 'fleeagt', 'mort', 'fleefrom', 'felix')\n",
        "    E3objects = token_vectors['felix'] + token_vectors['mort']\n",
        "    E3 = base_vectors['cause'] + E3objects + E3bite + E3flee + \\\n",
        "         circular_convolve(base_vectors['causeantc'], E3bite) + \\\n",
        "         circular_convolve(base_vectors['causecnsq'], E3flee)\n",
        "    episodes['E3'] = E3\n",
        "\n",
        "    # E4: Mort bit Felix, causing Felix to flee from Mort\n",
        "    E4bite = build_event('bite', 'biteagt', 'mort', 'biteobj', 'felix')\n",
        "    E4flee = build_event('flee', 'fleeagt', 'felix', 'fleefrom', 'mort')\n",
        "    E4objects = token_vectors['mort'] + token_vectors['felix']\n",
        "    E4 = base_vectors['cause'] + E4objects + E4bite + E4flee + \\\n",
        "         circular_convolve(base_vectors['causeantc'], E4bite) + \\\n",
        "         circular_convolve(base_vectors['causecnsq'], E4flee)\n",
        "    episodes['E4'] = E4\n",
        "\n",
        "    # E5: Rover bit Fred, causing Rover to flee from Fred\n",
        "    E5bite = build_event('bite', 'biteagt', 'rover', 'biteobj', 'fred')\n",
        "    E5flee = build_event('flee', 'fleeagt', 'rover', 'fleefrom', 'fred')\n",
        "    E5objects = token_vectors['rover'] + token_vectors['fred']\n",
        "    E5 = base_vectors['cause'] + E5objects + E5bite + E5flee + \\\n",
        "         circular_convolve(base_vectors['causeantc'], E5bite) + \\\n",
        "         circular_convolve(base_vectors['causecnsq'], E5flee)\n",
        "    episodes['E5'] = E5\n",
        "\n",
        "    # E6: John fled from Fido, causing Fido to bite John\n",
        "    E6bite = build_event('bite', 'biteagt', 'fido', 'biteobj', 'john')\n",
        "    E6flee = build_event('flee', 'fleeagt', 'john', 'fleefrom', 'fido')\n",
        "    E6objects = token_vectors['john'] + token_vectors['fido']\n",
        "    E6 = base_vectors['cause'] + E6objects + E6bite + E6flee + \\\n",
        "         circular_convolve(base_vectors['causeantc'], E6flee) + \\\n",
        "         circular_convolve(base_vectors['causecnsq'], E6bite)\n",
        "    episodes['E6'] = E6\n",
        "\n",
        "    # E7: Mort bit Felix, causing Mort to flee from Felix\n",
        "    E7bite = build_event('bite', 'biteagt', 'mort', 'biteobj', 'felix')\n",
        "    E7flee = build_event('flee', 'fleeagt', 'mort', 'fleefrom', 'felix')\n",
        "    E7objects = token_vectors['mort'] + token_vectors['felix']\n",
        "    E7 = base_vectors['cause'] + E7objects + E7bite + E7flee + \\\n",
        "         circular_convolve(base_vectors['causeantc'], E7bite) + \\\n",
        "         circular_convolve(base_vectors['causecnsq'], E7flee)\n",
        "    episodes['E7'] = E7\n",
        "\n",
        "    # E8: Mort fled from Felix, causing Felix to bite Mort\n",
        "    E8bite = build_event('bite', 'biteagt', 'felix', 'biteobj', 'mort')\n",
        "    E8flee = build_event('flee', 'fleeagt', 'mort', 'fleefrom', 'felix')\n",
        "    E8objects = token_vectors['mort'] + token_vectors['felix']\n",
        "    E8 = base_vectors['cause'] + E8objects + E8bite + E8flee + \\\n",
        "         circular_convolve(base_vectors['causeantc'], E8flee) + \\\n",
        "         circular_convolve(base_vectors['causecnsq'], E8bite)\n",
        "    episodes['E8'] = E8\n",
        "\n",
        "    # E9: Fido bit John, John fled from Fido\n",
        "    E9bite = build_event('bite', 'biteagt', 'fido', 'biteobj', 'john')\n",
        "    E9flee = build_event('flee', 'fleeagt', 'john', 'fleefrom', 'fido')\n",
        "    E9objects = token_vectors['john'] + token_vectors['fido']\n",
        "    E9 = E9objects + E9bite + E9flee\n",
        "    episodes['E9'] = E9\n",
        "\n",
        "    # E10: Fred stroked Rover, causing Rover to lick Fred\n",
        "    E10stroke = build_event('stroke', 'strokeagt', 'fred', 'strokeobj', 'rover')\n",
        "    E10lick = build_event('lick', 'lickagt', 'rover', 'lickobj', 'fred')\n",
        "    E10objects = token_vectors['fred'] + token_vectors['rover']\n",
        "    E10 = base_vectors['cause'] + E10objects + E10stroke + E10lick + \\\n",
        "          circular_convolve(base_vectors['causeantc'], E10stroke) + \\\n",
        "          circular_convolve(base_vectors['causecnsq'], E10lick)\n",
        "    episodes['E10'] = E10\n",
        "\n",
        "    # E11: Fred stroked Rover, Rover licked Fred\n",
        "    E11stroke = build_event('stroke', 'strokeagt', 'fred', 'strokeobj', 'rover')\n",
        "    E11lick = build_event('lick', 'lickagt', 'rover', 'lickobj', 'fred')\n",
        "    E11objects = token_vectors['fred'] + token_vectors['rover']\n",
        "    E11 = E11objects + E11stroke + E11lick\n",
        "    episodes['E11'] = E11\n",
        "\n",
        "    # Compute dot products (similarities) between probe and episodes\n",
        "    dot_products = {}\n",
        "    for key in episodes:\n",
        "        dot_products[key] = np.dot(P, episodes[key])\n",
        "\n",
        "    return dot_products\n",
        "\n",
        "def main():\n",
        "    n_runs = 500  # Number of simulation runs\n",
        "    episode_keys = ['E1', 'E2', 'E3', 'E4', 'E5', 'E6', 'E7', 'E8', 'E9', 'E10', 'E11']\n",
        "    results = {key: [] for key in episode_keys}\n",
        "\n",
        "    # Store similarity results for each episode\n",
        "    for i in range(n_runs):\n",
        "        dot_products = simulate()\n",
        "        for key in episode_keys:\n",
        "            results[key].append(dot_products[key])\n",
        "\n",
        "    # Compute mean and standard deviation\n",
        "    print(\"Aspects of similarity Dot-products\")\n",
        "    print(\"Episodes in long-term memory: Type Avg Sd\")\n",
        "    for key in episode_keys:\n",
        "        avg = np.mean(results[key])\n",
        "        sd = np.std(results[key])\n",
        "        print(f\"{key}: Avg {avg:.2f} Sd {sd:.3f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbCeNaBAAxh6",
        "outputId": "082105cc-b477-45ce-fda6-99857d74b4f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aspects of similarity Dot-products\n",
            "Episodes in long-term memory: Type Avg Sd\n",
            "E1: Avg 10.01 Sd 0.472\n",
            "E2: Avg 5.96 Sd 0.455\n",
            "E3: Avg 5.01 Sd 0.400\n",
            "E4: Avg 4.99 Sd 0.408\n",
            "E5: Avg 7.99 Sd 0.463\n",
            "E6: Avg 6.00 Sd 0.466\n",
            "E7: Avg 5.01 Sd 0.388\n",
            "E8: Avg 3.01 Sd 0.390\n",
            "E9: Avg 4.99 Sd 0.280\n",
            "E10: Avg 2.01 Sd 0.378\n",
            "E11: Avg 1.00 Sd 0.256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dot products between the probe episode P and episodes E1 to E11 vary in a manner reflecting their analogical similarities categorized by Plate. Episodes like E1 share both surface features and relational structures with P (Literal Similarity); thus, they have higher dot products, showing a strong similarity. Episodes such as E2, E3, and E4 represent Analogies which makes dot products moderate since they share relational structures but differ in objects. By contrast, episodes such as E10 and E11 are much less relationally or superficially similar to P (Objects only) and have correspondingly low dot products.\n",
        "\n",
        "The dot product provides reasonable estimates of analogical similarity, as it captures both the relational structures and the specific role-filler bindings of the episodes. Since the episodes were encoded using Holographic Reduced Representations, various aspects of the similarity are represented, including object attributes, first-order relations, and higher-order relational structures. It is a holistic representation that allows the dot product to capture the degree to which two episodes are analogous in their underlying relational architecture.\n",
        "\n",
        "These findings are in concert with Plate's discourse on the dimensions of similarity, showing that analogical reasoning is powerfully modeled under the HRR framework. The dot product similarities capture varieties of analogical similarity since episodes sharing more critical aspects, such as higher-order relations with consistent role mappings, have higher dot products. This suggests that the HRR model effectively captures the structural and relational correspondences that are central to human analogical reasoning."
      ],
      "metadata": {
        "id": "TkB20gSj8n6v"
      }
    }
  ]
}